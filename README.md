<div align="center">

# ğŸš€ UIPro: Unleashing Superior Interaction Capability For GUI Agents

### ğŸ¯ ICCV 2025 â€¢ Next-Generation AI GUI Automation

<p align="center">
  <img src="https://img.shields.io/badge/ğŸ”¬_Research-ICCV_2025-FF6B6B?style=for-the-badge&labelColor=1A1A2E&color=FF6B6B" alt="Research Badge"/>
  <img src="https://img.shields.io/badge/ğŸ¤–_AI-Multi--Modal-00D4FF?style=for-the-badge&labelColor=1A1A2E&color=00D4FF" alt="AI Badge"/>
  <img src="https://img.shields.io/badge/âš¡_Performance-SOTA-FFD93D?style=for-the-badge&labelColor=1A1A2E&color=FFD93D" alt="Performance Badge"/>
</p>

<p align="center">
  <a href="https://arxiv.org/abs/2406.08487">
    <img src="https://img.shields.io/badge/ğŸ“„_Paper-arXiv-B892FF?style=for-the-badge&logo=arxiv&logoColor=white&labelColor=1A1A2E" alt="Paper"/>
  </a>
  <a href="https://huggingface.co/collections/yifanzhang114/slime-665bcb2d0d71762b86fdbd2d">
    <img src="https://img.shields.io/badge/ğŸ¤—_Models-Hugging_Face-FFB86C?style=for-the-badge&logo=huggingface&logoColor=white&labelColor=1A1A2E" alt="Models"/>
  </a>
  <a href="https://huggingface.co/datasets/yifanzhang114/SMR">
    <img src="https://img.shields.io/badge/ğŸ“Š_Dataset-Hugging_Face-6BCF7F?style=for-the-badge&logo=huggingface&logoColor=white&labelColor=1A1A2E" alt="Dataset"/>
  </a>
</p>

<img src="assets/uipro_github_banner.png" alt="UIPro Project Banner" style="border-radius: 15px; box-shadow: 0 10px 30px rgba(0,0,0,0.3); margin: 20px 0;"/>

</div>

---

<div align="center">

## ğŸŒŸ **Revolutionary GUI Agent Technology**

*UIPro represents a paradigm shift in GUI automation, achieving human-level interaction capabilities across multiple platforms through advanced AI*

</div>

### ğŸ¨ **What Makes UIPro Special**

<table>
<tr>
<td width="50%" valign="top">

#### ğŸ§  **Intelligent Understanding**
- ğŸ“Š **20.6M** GUI understanding tasks
- ğŸ–¼ï¸ **2.5M** unique screenshots  
- ğŸ¯ **13** diverse task types
- ğŸ”„ Advanced denoising pipeline

</td>
<td width="50%" valign="top">

#### âš¡ **Superior Performance**
- ğŸ† **State-of-the-art** on multiple benchmarks
- ğŸš€ **68-85%** success rates across platforms
- ğŸ® **Unified action space** framework
- ğŸŒ **Cross-platform** compatibility

</td>
</tr>
</table>

---

<div align="center">

## ğŸ—ï¸ **Architecture & Training Pipeline**

*A two-stage revolutionary approach to GUI agent development*

</div>

<img src="assets/uipro_mainfigure.png" alt="UIPro Methodology Diagram" style="width: 100%; border-radius: 10px; margin: 20px 0;"/>

<div align="center">

### ğŸ”„ **Two-Stage Training Process**

</div>

<table>
<tr>
<td width="50%" align="center">

#### ğŸ¯ **Stage 1: GUI Understanding**
```
ğŸ“š Pre-training Phase
â”œâ”€â”€ ğŸ§  Element grounding
â”œâ”€â”€ ğŸ” Function recognition  
â”œâ”€â”€ ğŸ¯ Intent mapping
â””â”€â”€ ğŸ“Š Massive dataset learning
```

</td>
<td width="50%" align="center">

#### âš¡ **Stage 2: Agent Fine-tuning**
```
ğŸ® Action Execution Phase
â”œâ”€â”€ ğŸ“‹ Task planning
â”œâ”€â”€ ğŸ–±ï¸ Precise interactions
â”œâ”€â”€ ğŸŒ Cross-platform ops
â””â”€â”€ ğŸ¯ Unified action space
```

</td>
</tr>
</table>

---

<div align="center">

## ğŸ¯ **Core Capabilities**

</div>

<details>
<summary><b>ğŸ§  GUI Understanding Capabilities</b></summary>

<br>

| Capability | Description | Performance |
|------------|-------------|-------------|
| **ğŸ¯ Element Grounding** | Accurately locates UI elements based on descriptions | â­â­â­â­â­ |
| **ğŸ” Functionality Recognition** | Understands purpose and function of interface components | â­â­â­â­â­ |
| **ğŸ§­ Intent Mapping** | Connects user intentions to appropriate UI interactions | â­â­â­â­â­ |

</details>

<details>
<summary><b>ğŸ¤– GUI Agent Task Execution</b></summary>

<br>

| Capability | Description | Performance |
|------------|-------------|-------------|
| **ğŸ“‹ Task Planning** | Breaks down complex requests into actionable steps | â­â­â­â­â­ |
| **âš¡ Action Execution** | Performs clicks, typing, scrolling with high precision | â­â­â­â­â­ |
| **ğŸŒ Cross-Platform Navigation** | Seamless operation across different device types | â­â­â­â­â­ |

</details>

---

<div align="center">

## ğŸ“Š **Performance Benchmarks**

*Industry-leading results across all major GUI benchmarks*

</div>

### ğŸ† **GUI Agent Task Evaluation**

<div align="center">

| ğŸ¯ **Benchmark** | ğŸ¤– **UIPro-SLiME (3B)** | ğŸš€ **UIPro-Qwen2VL (7B)** | ğŸ“Š **Metric** |
|:---------------:|:----------------------:|:------------------------:|:------------:|
| **AITW** | <span style="color: #00D4FF; font-weight: bold;">68.0%</span> | <span style="color: #FF6B6B; font-weight: bold;">70.4%</span> | Step SR |
| **AndroidControl** | <span style="color: #00D4FF; font-weight: bold;">61.1%</span> | <span style="color: #FF6B6B; font-weight: bold;">85.5%</span> | Step SR |
| **GUIAct-Web** | <span style="color: #00D4FF; font-weight: bold;">68.2%</span> | <span style="color: #FF6B6B; font-weight: bold;">69.1%</span> | Step SR |
| **Mind2Web** | <span style="color: #00D4FF; font-weight: bold;">28.7%</span> | <span style="color: #FF6B6B; font-weight: bold;">48.4%</span> | Step SR |

<small><i>Step Success Rate (Step SR) - Higher is better</i></small>

</div>

---

<div align="center">

## ğŸš€ **Quick Start Guide**

*Get up and running with UIPro in minutes*

</div>

### ğŸ“¦ **Installation**

<details>
<summary><b>ğŸ”§ Setup Instructions</b></summary>

<br>

#### 1ï¸âƒ£ **Clone Repository**
```bash
git clone https://github.com/ZJULiHongxin/UIPro.git
cd UIPro
```

#### 2ï¸âƒ£ **Install Dependencies**
```bash
pip install -r requirements.txt
```

</details>

### ğŸ’¡ **Basic Usage**

<details>
<summary><b>ğŸ® Quick Example</b></summary>

<br>

```python
from uipro import UIPro

# Initialize the model
model = UIPro.from_pretrained("uipro-qwen2vl-7b")

# Your GUI automation code here
```

</details>

---

<div align="center">

## ğŸ“š **Dataset: The Foundation of Excellence**

*The world's largest and most comprehensive GUI understanding collection*

</div>

<div align="center">

### ğŸ“Š **Dataset Statistics**

| Metric | Value | Description |
|:------:|:-----:|:-----------:|
| ğŸ“ **Task Samples** | **20.6M** | GUI understanding tasks |
| ğŸ–¼ï¸ **Screenshots** | **2.5M** | Unique GUI screenshots |
| ğŸ¯ **Elements** | **3.3M** | Clean GUI elements |
| ğŸ”¢ **Task Types** | **13** | Different task categories |

</div>

### ğŸ—ï¸ **Data Compilation Pipeline**

<details>
<summary><b>ğŸ”§ General Setup Instructions</b></summary>

<br>

First of all, create a root folder saving all raw data and a folder saving processed training samples.

> **Note**: We also implemented a systematic denoising procedure to ensure data quality, removing up to 29% of noise from some data sources.

</details>

<details>
<summary><b>ğŸ“± Android in the Wild (AiTW)</b></summary>

<br>

First download the AiTW screenshots from [this URL](https://box.nju.edu.cn/f/96ba5115bae24eaaa44e/) and the annotations from [this URL](https://box.nju.edu.cn/f/1245c74fc09b4565a235/), and then unzip and place them in a folder like:

<details>
<summary><b>ğŸ“‚ Directory Structure</b></summary>

```
root/
â”œâ”€â”€ AITW/
â”‚   â”œâ”€â”€ aitw_data_test.json
â”‚   â”œâ”€â”€ aitw_data_train.json
â”‚   â”œâ”€â”€ aitw_data_val.json
â”‚   â””â”€â”€ aitw_images/
â”‚       â”œâ”€â”€ general/
â”‚       â”œâ”€â”€ gogleapps/
â”‚       â”œâ”€â”€ install/
â”‚       â”œâ”€â”€ single/
â”‚       â””â”€â”€ webshopping/
```

</details>

<details>
<summary><b>âš™ï¸ Processing Instructions</b></summary>

Next, modify the `ROOT`, `SAVE_DIR`, `SPLIT`, `POINT_FORMAT` in `utils/data_utils/make_aitw_data/make_aitw_data.py` and then run:

```bash
python utils/data_utils/make_aitw_data/make_aitw_data.py
```

Finally, the processed training samples will be saved in `SAVE_DIR/AITW_processed`.

</details>

</details>

<details>
<summary><b>ğŸ¦“ Android in the Zoo (AitZ)</b></summary>

<br>

First download the raw data according to the instructions in [the AitZ Github Repo](https://github.com/IMNearth/CoAT), and then unzip and place them in a folder like:

<details>
<summary><b>ğŸ“‚ Directory Structure</b></summary>

```
root/
â”œâ”€â”€ AITZ/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ general/
â”‚   â”‚   â”œâ”€â”€ googleapps/
â”‚   â”‚   â”œâ”€â”€ install/
â”‚   â”‚   â”œâ”€â”€ single/
â”‚   â”‚   â””â”€â”€ webshopping/
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ general/
â”‚       â”œâ”€â”€ googleapps/
â”‚       â”œâ”€â”€ install/
â”‚       â””â”€â”€ webshopping/
```

</details>

<details>
<summary><b>âš™ï¸ Processing Instructions</b></summary>

Next, modify the `ROOT`, `SAVE_DIR`, `SPLIT`, `POINT_FORMAT` in `utils/data_utils/make_aitw_data/make_aitw_data.py` and then run:

```bash
python utils/data_utils/make_aitw_data/make_aitw_data.py
```

Finally, the processed training samples will be saved in `SAVE_DIR/AITW_processed`.

</details>

</details>

<details>
<summary><b>ğŸ® AndroidControl</b></summary>

<br>

First download the raw data according to the instructions in [the AndroidControl Github Repo](https://github.com/google-research/google-research/blob/master/android_control/README.md), and then unzip and place them in a folder like:

<details>
<summary><b>ğŸ“‚ Directory Structure</b></summary>

```
root/
â”œâ”€â”€ AndroidControl/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ android_control-00000-of-00020
â”‚   â”‚   â”œâ”€â”€ android_control-00001-of-00020
â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ android_control-00019-of-00020
â”‚   â”‚   â””â”€â”€ splits.json
```

</details>

<details>
<summary><b>âš™ï¸ Processing Instructions</b></summary>

Next, modify the `ANDROIDCONTROL_ROOT`, `SAVE_DIR`, `SPLIT`, `POINT_FORMAT` in `utils/data_utils/make_androidcontrol_data/make_androidcontrol_data.py` and then run:

```bash
python utils/data_utils/make_androidcontrol_data/make_androidcontrol_data.py
```

Finally, the processed training samples will be saved in `SAVE_DIR/AndroidControl_processed` and the extracted screenshot images will be saved in `ANDROIDCONTROL_ROOT/images`.

</details>

</details>

<details>
<summary><b>ğŸŒŠ GUIOdyssey</b></summary>

<br>

First download the raw data according to the instructions in [the GUIOdyssey HF Repo](https://huggingface.co/datasets/hflqf88888/GUIOdyssey), and then unzip and place them in a folder like:

<details>
<summary><b>ğŸ“‚ Initial Directory Structure</b></summary>

```
root/
â”œâ”€â”€ GUIOdyssey_raw/
â”‚   â”œâ”€â”€ screenshots/
â”‚   â”‚   â”œâ”€â”€ data_0/
â”‚   â”‚   â”œâ”€â”€ data_1/
â”‚   â”‚   â”œâ”€â”€ data_2/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ splits/
â”‚   â””â”€â”€ annotations/
```

</details>

<details>
<summary><b>ğŸ“ Reorganize Screenshots</b></summary>

Next, move all images in the `data_*` subfolders under `screenshots` to `screenshots`, like this:

```
root/
â”œâ”€â”€ GUIOdyssey_raw/
â”‚   â”œâ”€â”€ screenshots/
â”‚   â”‚   â”œâ”€â”€ 2386365564178401_9.png
â”‚   â”‚   â”œâ”€â”€ 5022534067657028_12.png
â”‚   â”‚   â”œâ”€â”€ 7287738713744873_13.png
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ splits/
â”‚   â””â”€â”€ annotations/
```

</details>

<details>
<summary><b>âš™ï¸ Processing Instructions</b></summary>

Next, modify the `ANDROIDCONTROL_ROOT`, `SAVE_DIR`, `SPLIT`, `POINT_FORMAT` in `utils/data_utils/make_guiodyssey_data/make_guiodyssey_data.py` and then run:

```bash
python utils/data_utils/make_guiodyssey_data/make_guiodyssey_data.py
```

Finally, the processed training samples will be saved in `SAVE_DIR/GUIOdyssey_processed` and the extracted screenshot images will be saved in the appropriate directory.

</details>

</details>


<details>
<summary><b>AMEX</b></summary>

<br>

First download the raw data according to the instructions in [the AMEX HF Repo](https://huggingface.co/datasets/Yuxiang007/AMEX), and then unzip and place them in a folder like:

<details>
<summary><b>ğŸ“‚ Initial Directory Structure</b></summary>

```
root/
â”œâ”€â”€ AMEX/
â”‚   â”œâ”€â”€ element_anno/
â”‚   â”œâ”€â”€ screenshot/
â”‚   â””â”€â”€ metadata/
```

</details>

<details>
<summary><b>âš™ï¸ Processing Instructions</b></summary>

Next, modify the `ANDROIDCONTROL_ROOT`, `SAVE_DIR`, `SPLIT`, `POINT_FORMAT` in `utils/data_utils/make_guiodyssey_data/make_guiodyssey_data.py` and then run:

```bash
python utils/data_utils/make_guiodyssey_data/make_guiodyssey_data.py
```

Finally, the processed training samples will be saved in `SAVE_DIR/GUIOdyssey_processed` and the extracted screenshot images will be saved in the appropriate directory.

</details>

</details>


<details>
<summary><b>GUIAct</b></summary>

<br>

First download the raw data from [the GUIAct HF Repo](https://huggingface.co/datasets/yiye2023/GUIAct), and then place them in a folder like:

<details>
<summary><b>ğŸ“‚ Initial Directory Structure</b></summary>

```
root/
â”œâ”€â”€ GUICourse/
â”‚   â”œâ”€â”€ GUIAct/
â”‚   â”‚   â”œâ”€â”€ smartphone_test_data.json
â”‚   â”‚   â”œâ”€â”€ smartphone_test_images.parquet
â”‚   â”‚   â”œâ”€â”€ smartphone_train_data.json
â”‚   â”‚   â””â”€â”€ ...
```

</details>

<details>
<summary><b>âš™ï¸ Processing Instructions</b></summary>

Next, set `SUBTASK=['GUIAct']`, modify the `DATA_ROOT`, `SAVE_DIR`, `CURRENT_SPLIT`, `CURRENT_DEVICE_TYPE` in `utils/data_utils/make_guicourse_data/make_guicourse_data.py` and then run:

```bash
python utils/data_utils/make_guicourse_data/make_guicourse_data.py
```

Finally, the processed training samples will be saved in `SAVE_DIR/GUICourse_processed` and the extracted screenshot images will be saved in the appropriate directory.

</details>

</details>

<details>
<summary><b>GUIAct</b></summary>

<br>

First download the raw data from [the GUIAct HF Repo](https://huggingface.co/datasets/yiye2023/GUIAct), and then place them in a folder like:

<details>
<summary><b>ğŸ“‚ Initial Directory Structure</b></summary>

```
root/
â”œâ”€â”€ GUICourse/
â”‚   â”œâ”€â”€ GUIAct/
â”‚   â”‚   â”œâ”€â”€ smartphone_test_data.json
â”‚   â”‚   â”œâ”€â”€ smartphone_test_images.parquet
â”‚   â”‚   â”œâ”€â”€ smartphone_train_data.json
â”‚   â”‚   â””â”€â”€ ...
```

</details>

<details>
<summary><b>âš™ï¸ Processing Instructions</b></summary>

Next, modify the `DATA_ROOT`, `SAVE_DIR`, `SPLIT`, `DEVICE_TYPE` in `utils/data_utils/make_guicourse_data/make_guicourse_data.py` and then run:

```bash
python utils/data_utils/make_guicourse_data/make_guicourse_data.py
```

Finally, the processed training samples will be saved in `SAVE_DIR/GUICourse_processed` and the extracted screenshot images will be saved in the appropriate directory.

</details>

</details>

---

<div align="center">

## ğŸ”¬ **Technical Deep Dive**

*Advanced technical details for researchers and developers*

</div>

### ğŸ® **Unified Action Space Design**

<details>
<summary><b>ğŸ“± Mobile Action Framework</b></summary>

<br>

```json
{
  "mobile_actions": [
    "tap", "long_press", "drag", "input_text",
    "navigate_home", "navigate_back", "navigate_recent",
    "press_enter", "swipe", "wait", "status_complete"
  ]
}
```

</details>

<details>
<summary><b>âš¡ Unified Swipe Action</b></summary>

<br>

```json
{
  "action": "swipe",
  "start": [x, y],          // Starting coordinates
  "direction": "up",        // Movement direction  
  "distance": 200           // Swipe distance in pixels
}
```

</details>

---

<div align="center">

## ğŸ“ **Citation**

*If you use UIPro in your research, please cite our paper*

</div>

```bibtex
@inproceedings{li2025uipro,
  title={UIPro: Unleashing Superior Interaction Capability For GUI Agents},
  author={Li, Hongxin and Su, Jingran and Chen, Jingfan and Ju, Zheng and Chen, Yuntao and Li, Qing and Zhang, Zhaoxiang},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  year={2025}
}
```

---

<div align="center">

## ğŸ‘¥ **Team & Acknowledgments**

*Special thanks to our research team and the open-source community*

<p>
This work was supported in part by the <b>National Key R&D Program of China</b> and the <b>National Natural Science Foundation of China</b>. We extend our gratitude to the open-source community for providing foundational datasets and tools that made this research possible.
</p>

<br>

---

<br>

## â­ **Star this repository if you find UIPro helpful!** â­

<a href="https://github.com/ZJULiHongxin/UIPro/stargazers">
  <img src="https://img.shields.io/github/stars/ZJULiHongxin/UIPro?style=for-the-badge&logo=github&logoColor=white&labelColor=1A1A2E&color=FFD93D" alt="GitHub Stars"/>
</a>

<br><br>

<p><i>ğŸš€ Revolutionizing GUI automation, one interaction at a time</i></p>

</div>